{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover Python Regular Expressions\n",
    "<p style='text-align:justify;'>- Regular expressions are used to identify whether a pattern exists in a given sequence of characters (string) or not. They help in manipulating textual data, which is often a pre-requisite for data science projects that involve text mining. You must to have come across some application of regular expressions: they are used at the server side to validate the format of email addresses or password during registration, used for parsing text data files to find, replace or delete certain string, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regular Expression in Python__\n",
    "- In Python, regular expressions are supported by the `re` module. That means that if you want to start using them in your Python scripts, you have to import this module with the help of `import`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `re`\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Patterns: Ordinary Characters__\n",
    "- You can easily tackle many basic patterns in Python using the ordinary characters. Ordinary characters are the simplest regular expressions. They match themselves exactly and do not have a speacial meaning in their regular expression syntax.\n",
    "\n",
    "Example are 'A', 'a', 'X', '5'.\n",
    "\n",
    "- Ordinary characters can be used to perform simple exact matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match!\n"
     ]
    }
   ],
   "source": [
    "pattern = r'Cookie'\n",
    "sequence = 'Cookie'\n",
    "if re.match(pattern, sequence):\n",
    "    print('Match!')\n",
    "else:\n",
    "    print('Not a match!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `match()` function returns a match object if the text matches the pattern. Otherwise it returns None. The re module also contains several other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'ASCII',\n",
       " 'DEBUG',\n",
       " 'DOTALL',\n",
       " 'I',\n",
       " 'IGNORECASE',\n",
       " 'L',\n",
       " 'LOCALE',\n",
       " 'M',\n",
       " 'MULTILINE',\n",
       " 'RegexFlag',\n",
       " 'S',\n",
       " 'Scanner',\n",
       " 'T',\n",
       " 'TEMPLATE',\n",
       " 'U',\n",
       " 'UNICODE',\n",
       " 'VERBOSE',\n",
       " 'X',\n",
       " '_MAXCACHE',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_alphanum_bytes',\n",
       " '_alphanum_str',\n",
       " '_cache',\n",
       " '_compile',\n",
       " '_compile_repl',\n",
       " '_expand',\n",
       " '_locale',\n",
       " '_pattern_type',\n",
       " '_pickle',\n",
       " '_subx',\n",
       " 'compile',\n",
       " 'copyreg',\n",
       " 'enum',\n",
       " 'error',\n",
       " 'escape',\n",
       " 'findall',\n",
       " 'finditer',\n",
       " 'fullmatch',\n",
       " 'functools',\n",
       " 'match',\n",
       " 'purge',\n",
       " 'search',\n",
       " 'split',\n",
       " 'sre_compile',\n",
       " 'sre_parse',\n",
       " 'sub',\n",
       " 'subn',\n",
       " 'template']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Wild Card Characters: Special Characters__\n",
    "- Special characters are characters which do not match themselves as seen but actually have a special meaning when used in a regular expression.\n",
    "- The most widely used special characters are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.`- A period. Matches any single charater except newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cookie'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'Co.k.e', 'Cookie').group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\\w`- Lowercase w. Matches any single letter, digit or underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cookie'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'Co\\wk\\we', 'Cookie').group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------\n",
    "__Introducing our data set__\n",
    "- __Context:__\n",
    "\n",
    "    - Fraudulent e-mails contain criminally deceptive information, usually with the intent of convincing the recipient to give the sender a large amount of money. Perhaps the best known type of fraudulent e-mails is the __Nigerian Letter or “419”__ Fraud.\n",
    "\n",
    "- __Content:__\n",
    "\n",
    "    - This dataset is a collection of more than 2,500 \"Nigerian\" Fraud Letters, dating from 1998 to 2007.<br>\n",
    "    - These emails are in a single text file. Each e-mail has a header which includes the following information:\n",
    "\n",
    "        - Return-Path: address the email was sent from\n",
    "        - X-Sieve: the X-Sieve host (always cmu-sieve 2.0)\n",
    "        - Message-Id: a unique identifier for each message\n",
    "        - From: the message sender (sometimes blank)\n",
    "        - Reply-To: the email address to which replies will be sent\n",
    "        - To: the email address to which the e-mail was originally set (some are truncated for anonymity)\n",
    "        - Date: Date e-mail was sent\n",
    "        - Subject: Subject line of e-mail\n",
    "        - X-Mailer: The platform the e-mail was sent from\n",
    "        - MIME-Version: The Multipurpose Internet Mail Extension version\n",
    "        - Content-Type: type of content & character encoding\n",
    "        - Content-Transfer-Encoding: encoding in bits\n",
    "        - X-MIME-Autoconverted: the type of autoconversion done\n",
    "        - Status: r (read) and o (opened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Introducing Python's regex module__\n",
    "- First, prepare the data set by opening the text file, setting it to read-only, and reading it. We also assign it to a variable, `fh` ('file handle')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(r'test_emails.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we precede the directory path with an `r`. This technique converts a string into a raw string, which helps to avoid conflicts caused by how some machines read characters, such as backslashes in directory paths on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose we want to find out who the emails are from. We could try raw Python on its own:\n",
    "```python\n",
    "for line in fh.split('\\n'):\n",
    "    if 'From:' in line:\n",
    "        print(line)\n",
    "```\n",
    "Or, we could use regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob.com>\n",
      "From: \"Mr. Ben Suleman\" <bensul2004nng@spinfinder.com>\n",
      "From: \"PRINCE OBONG ELEME\" <obong_715@epatra.com>\n",
      "From: \"PRINCE OBONG ELEME\" <obong_715@epatra.com>\n",
      "From: \"Maryam Abacha\" <m_abacha03@www.com>\n"
     ]
    }
   ],
   "source": [
    "for line in fh.split('\\n'):\n",
    "    if 'From:' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob.com>\n",
      "From: \"Mr. Ben Suleman\" <bensul2004nng@spinfinder.com>\n",
      "From: \"PRINCE OBONG ELEME\" <obong_715@epatra.com>\n",
      "From: \"PRINCE OBONG ELEME\" <obong_715@epatra.com>\n",
      "From: \"Maryam Abacha\" <m_abacha03@www.com>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for line in re.findall('From: .*', fh):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`re.findall()`returns a list of all instances of the pattern in the string. It's one of the most popular functions in Python's built-in `re` module. Let's break it down. The function takes two arguments in the form of `re.findall(pattern, string)`. Here, `pattern` represents the substring we want to find, and `string` represents the main string we want to find it in. The main string can consist of multiple lines.\n",
    "\n",
    "`.*` are shorthand for string patterns. We'll explain them in detail very, very soon. Suffice to say for now that they match the name and email address in the `From:` field.\n",
    "\n",
    "Let's take our first look at some common regex patterns before we dive deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Common regex patterns__<br>\n",
    "\n",
    "The pattern we used with `re.findall()` above contains a fully spelt out string, `'From:'`. This is useful when we know precisely what we're looking for, right down to the actual letters and whether or not they're upper or lower case. If we don't know the exact format of the strings we want, we'd be lost. Fortunately, regex has basic patterns that account for this scenario. Let's look at the ones we use in this tutorial:\n",
    "\n",
    "- `\\w` matches alphanumeric characters, which means a-z, A-Z, and 0-9. It also matches the underscore, _, and the dash, -.\n",
    "\n",
    "- `\\d` matches digits, which means 0-9.\n",
    "\n",
    "- `\\s` matches whitespace characters, which include the tab, new line, carriage return, and space characters.\n",
    "\n",
    "- `\\S`  matches non-whitespace characters.\n",
    "\n",
    "- `.` matches any character except the new line character `\\n`.\n",
    "\n",
    "With these regex patterns in hand, you'll quickly understand our code above as we go on to explain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Working with regex patterns__<br>\n",
    "\n",
    "We can now explain the use of `.*` in the line `re.findall('From: .*', text)` above. Let's look at `.` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \n",
      "From: \n",
      "From: \n",
      "From: \n",
      "From: \n"
     ]
    }
   ],
   "source": [
    "for line in re.findall('From:.',fh):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding a `.` next to `From:`, we look for one additional character next to it. Because `.` looks for any character except `\\n`, it captures the space character, which we cannot see. We can try more dots to verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \"MR. JAMES \n",
      "From: \"Mr. Ben Su\n",
      "From: \"PRINCE OBO\n",
      "From: \"PRINCE OBO\n",
      "From: \"Maryam Aba\n"
     ]
    }
   ],
   "source": [
    "for line in re.findall('From:............', fh):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like adding dots does acquire the rest of the line for us. But, it's tedious and we don't know how many dots to add. This is where the asterisk symbol, `*`, plays a very useful role.\n",
    "- Let's construct a greedy search for `.` with `*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob.com>\n",
      "From: \"Mr. Ben Suleman\" <bensul2004nng@spinfinder.com>\n",
      "From: \"PRINCE OBONG ELEME\" <obong_715@epatra.com>\n",
      "From: \"PRINCE OBONG ELEME\" <obong_715@epatra.com>\n",
      "From: \"Maryam Abacha\" <m_abacha03@www.com>\n"
     ]
    }
   ],
   "source": [
    "for line in re.findall('From: .*', fh):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because `*` matches zero or more instances of the pattern indicated on its left, and `.` is on its left here, we are able to acquire all the characters in the `From:` field till the end of the line. This prints out the full line with beautifully succinct code.\n",
    "\n",
    "- We might even go further and isolate only the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"MR. JAMES NGOLA.\"']\n",
      "['\"Mr. Ben Suleman\"']\n",
      "['\"PRINCE OBONG ELEME\"']\n",
      "['\"PRINCE OBONG ELEME\"']\n",
      "['\"Maryam Abacha\"']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall('From: .*', fh)\n",
    "\n",
    "for line in match:\n",
    "    print(re.findall('\\\".*\\\"', line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We iterate through the list. In each cycle, we perform `re.findall` again. This time, the function starts by matching the first quotation mark.\n",
    "- Notice that we use a backslash next to the first quotation mark. The backslash is a special character used for escaping other special characters. For instance, when we want to use a quotation mark as a string literal instead of a special character, we escape it with a backslash like this: `\\\"`. If we do not escape the pattern above with backslashes, it would become `\"\".*\"\"`, which the Python interpreter would read as a period and an asterisk between two empty strings. It would produce an error and break the script. Hence, it's crucial that we escape the quotation marks here with backslashes.\n",
    "- After the first quotation mark is matched, `.*` acquires all the characters in the line until the next quotation mark, also escaped in the pattern. This gets us just the name, within quotation marks. Each name is also printed within square brackets because `re.findall` returns matches in a list.\n",
    "- What if we want the email address instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['james_ngola2002@maktoob.com']\n",
      "['bensul2004nng@spinfinder.com']\n",
      "['obong_715@epatra.com']\n",
      "['obong_715@epatra.com']\n",
      "['m_abacha03@www.com']\n"
     ]
    }
   ],
   "source": [
    "for line in match:\n",
    "    print(re.findall('\\w\\S*@.*\\w', line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we match just the front part of the email address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['james_ngola2002@']\n",
      "['bensul2004nng@']\n",
      "['obong_715@']\n",
      "['obong_715@']\n",
      "['m_abacha03@']\n"
     ]
    }
   ],
   "source": [
    "for line in match:\n",
    "    print(re.findall('\\w\\S*@', line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Emails always contain an `@` symbol, so we start with it. The part of the email before the `@` symbol might contain alphanumeric characters, which means `\\w` is required. However, because some emails contain a period or a dash, that's not enough. We add `\\S` to look for non-whitespace characters. But, `\\w\\S` will get only two characters. Add `*` to look for repetitions. The front part of the pattern thus looks like this: `\\w\\S*@`.\n",
    "- Now for the pattern behind the `@` symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@maktoob.com>']\n",
      "['@spinfinder.com>']\n",
      "['@epatra.com>']\n",
      "['@epatra.com>']\n",
      "['@www.com>']\n"
     ]
    }
   ],
   "source": [
    "for line in match:\n",
    "     print(re.findall('@.*', line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The domain name usually contains alphanumeric characters, periods, and a dash sometimes. This is simple, a `.` would do. To make it greedy, we extend the search with a `*`. This allows us to match any character till the end of the line.\n",
    "- If we look at the line closely, we see that each email is encapsulated within angle brackets, < and >. Our pattern, `.*`, includes the closing bracket, >.\n",
    "- Let's remedy it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@maktoob.com']\n",
      "['@spinfinder.com']\n",
      "['@epatra.com']\n",
      "['@epatra.com']\n",
      "['@www.com']\n"
     ]
    }
   ],
   "source": [
    "for line in match:\n",
    "    print(re.findall('@.*\\w', line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Email addresses end with an alphanumeric character, so we cap the pattern with `\\w`. Hence, the rear of the @ symbol is `.*\\w`, which means that the pattern we want is a group of any type of characters that ends with an alphanumeric character. This excludes `>`.\n",
    "- Our full email address pattern thus looks like this: `\\w\\S*@.*\\w`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Common regex functions__<br>\n",
    "`re.findall()` is undeniably useful, and the `re` module provides more equally convenient functions. These include:\n",
    "- `re.search()`\n",
    "- `re.split()`\n",
    "- `re.sub()`\n",
    "\n",
    "We'll take a gander at these one by one before using them to bring some order to the unwieldy mass of the Corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.search()__<br>\n",
    "While `re.findall()` matches all instances of a pattern in a string and returns them in list, `re.search()` matches the first instance of a pattern in a string, and returns it as a `re` match object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search('From:.*', fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_sre.SRE_Match"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(190, 244), match='From: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob>\n"
     ]
    }
   ],
   "source": [
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob.com>\n"
     ]
    }
   ],
   "source": [
    "print(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Like `re.findall()`, `re.search()` also takes two arguments. The first is the pattern to match, and the second is the string to find it in. Here, we've assigned the results to the `match` variable for neatness.\n",
    "- Because `re.search()` returns a `re` match object, we can't display the name and email address by printing it directly. Instead, we have to apply the `group()` function to it first. We've printed both their types out in the code above. As we can see, `group()` converts the match object into a string.\n",
    "- We can also see that printing `match` displays properties beyond the string itself, whereas printing `match.group()` displays only the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.split()__<br>\n",
    "Suppose we need a quick way to get the domain name of the email addresses. We could do it with three regex operations, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "james_ngola2002, maktoob.com\n",
      "bensul2004nng, spinfinder.com\n",
      "obong_715, epatra.com\n",
      "obong_715, epatra.com\n",
      "m_abacha03, www.com\n"
     ]
    }
   ],
   "source": [
    "address = re.findall('From: .*', fh)\n",
    "\n",
    "for item in address:\n",
    "    for line in re.findall('\\w\\S*@.*\\w', item):\n",
    "        username, domain_name = re.split('@', line)\n",
    "        print('{}, {}'.format(username, domain_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line is familiar. We return a list of strings, each containing the contents of the `From:` field, and assign it to a variable. Next, we iterate through the list to find the email addresses. At the same time, we iterate through the email addresses and use the `re` module's `split()` function to snip each address in half, with the @ symbol as the delimiter. Finally, we print it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__re.sub()__<br>\n",
    "Another handy `re` function is `re.sub()`. As the function name suggests, it substitutes parts of a string. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = re.search('From:.*', fh)\n",
    "address = sender.group()\n",
    "email = re.sub('From', 'Email', address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob.com>\n"
     ]
    }
   ],
   "source": [
    "print(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: \"MR. JAMES NGOLA.\" <james_ngola2002@maktoob.com>\n"
     ]
    }
   ],
   "source": [
    "print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, we've already seen the tasks on the first and second lines performed before. On the third line, we apply `re.sub()` on address, which is the full `From:` field in the email header.\n",
    "- `re.sub()` takes three arguments. The first is the substring to substitute, the second is a string we want in its place, and the third is the main string itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regex with pandas__\n",
    "- Now that we have the basics of regex in hand, we can try something much more sophisticated. However, we need to combine regex with the pandas Python data analysis library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sorting emails with regex and pandas__\n",
    "- The Corpus is a single text file containing thousands of emails. We'll use regex and pandas to sort the parts of each email into appropriate categories so that the Corpus can be more easily read or analysed.\n",
    "- We'll sort each email into the following categories:\n",
    "    - `sender_name`\n",
    "    - `sender_address`\n",
    "    - `recipient_address`\n",
    "    - `recipient_name`\n",
    "    - `date_sent`\n",
    "    - `subject`\n",
    "    - `email_body`\n",
    "- Each of these categories will become a column in our pandas dataframe or table. This is useful because it lets us work on each column on its own. For instance, we could write code to find out which domain names the emails come from, instead of coding to isolate the email addresses from the other parts first. Essentially, categorising the important parts of our data set allows us to write much more concise code to acquire granular information later on. In turn, concise code reduces the number of operations our machines have to do, which speeds up our analytical process, especially when working with massive data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preparing the script__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import email\n",
    "\n",
    "email = []\n",
    "\n",
    "fh = open(r'test_emails.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We first import the `re` and `pandas` modules as standard practice dictates, right at the top of the script. We import Python's `email` package as well, which is especially needed for the body of the email. The body of the email is rather complicated to work with using regex alone. It might even require enough cleaning up to warrant its own tutorial. So, we use the well-developed `email` package to save some time and let us focus on learning regex.\n",
    "- Next, we create an empty list, `emails`, which will store dictionaries. Each dictionary will contain the details of each email.\n",
    "- We print the results of our code to the screen frequently to illustrate where code goes right or wrong. However, because there are thousands of emails in the data set, this prints thousands of lines to the screen and clogs up this tutorial page. We certainly don't want to make you scroll down thousands of lines of results over and over again. Thus, as we've done at the beginning of the tutorial, we open and read a shorter version of the Corpus. We prepared it by hand just for the purposes of this tutorial. You can use the actual data set at home though. Every time we run a `print()` function, you'll print thousands of lines to the screen in barely a few seconds.\n",
    "\n",
    "Now, we begin applying regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = re.split(r'From r', fh)\n",
    "contents.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `re` module's split function to split the entire chunk of text in `fh` into a list of separate emails, which we assign to the variable `contents`. This is important because we want to work on the emails one by one, by iterating through the list with a for loop. But, how do we know to split by the string `\"From r\"`? We know this because we looked into the file before we wrote the script. We didn't have to peruse the thousands of emails in there. Just the first few, to see what the structure of the data looks like. As it so happens, each email is preceded by the string `\"From r\"`.\n",
    "\n",
    "One reason we use the Fraudulent Email Corpus in this tutorial is to show that when data is disorganised, unfamiliar, and comes without documentation, we can't rely solely on code to sort it out. It would require a pair of human eyes. As we've just shown, we had to look into the Corpus itself to study its structure. In addition, such data may require a lot of cleaning up, as does this Corpus. For instance, even though we count 3977 emails in this set using the full script we're about to construct for this tutorial, there are actually more. Some emails are not preceded by `\"From r\"`, and so are not split into their own. We leave our data set as it is for now, though, lest this tutorial never ends.\n",
    "\n",
    "Notice also that we use `contents.pop(0)` to get rid of the first element in the list. That's because a `\"From r\"` string precedes the first email. When that string is split, it produces an empty string at index 0. The script we're about to write is designed for emails. If it works on an empty string, it might throw up errors. Getting rid of the empty string lets us avoid these errors from breaking our script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Getting every name and address with a for loop__\n",
    "```python\n",
    "for item in contents:\n",
    "    emails_dict = {}\n",
    "```\n",
    "\n",
    "In the code above, we use a `for` loop to iterate through `contents` so we can work with each email in turn. We create a dictionary, `email_dict`, that will hold all the details of each email, such as the sender's address and name. In fact, these are the first items we find.\n",
    "- This is a three-step process. It begins by finding the `From:` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for item in contents: # First two lines again so that Jupyter runs the code.\n",
    "    emails_dict = {}\n",
    "\n",
    "# Find sender's email address and name.\n",
    "\n",
    "    # Step 1: find the whole line beginning with \"From:\".\n",
    "    sender = re.search(r\"From:.*\", item)\n",
    "```\n",
    "With __Step 1__, we find the entire `From:` field using the `re.search()` function. The `.` means any character except `\\n`, and `*` extends it to the end of the line. We then assign this to the variable `sender`.\n",
    "\n",
    "But, data isn't always straightforward. It can contain surprises. For instance, what if there's no `From:` field? The script would throw an error and break. We pre-empt errors from this scenario in __Step 2__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Step 2: find the email address and name.\n",
    "if sender is not None:\n",
    "    s_email = re.search(r\"\\w\\S*@.*\\w\", sender.group())\n",
    "    s_name = re.search(r\":.*<\", sender.group())\n",
    "else:\n",
    "    s_email = None\n",
    "    s_name = None\n",
    "```\n",
    "- To avoid errors resulting from missing `From:` fields, we use an `if` statement to check that `sender` isn't `None`. If it is, we assign `s_email` and `s_name` the value of `None` so that the script can move on instead of breaking unexpectedly.\n",
    "- In Step 2, we use a familiar regex pattern from before, `\\w\\S*@.*\\w`, which matches the email address.\n",
    "- We use a different tactic for the name. Each name is bounded by the colon, `:`, of the substring `\"From:\"` on the left, and by the opening angle bracket, `<`, of the email address on the right. Hence, we use `:.*<` to find the name. We get rid of `:` and `<` from each result in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(\"sender type: \" + str(type(sender)))\n",
    "print(\"sender.group() type: \" + str(type(sender.group())))\n",
    "print(\"sender: \" + str(sender))\n",
    "print(\"sender.group(): \" + str(sender.group()))\n",
    "print(\"\\n\")\n",
    "```\n",
    "Note that we're not using `sender` as the string to search for in each application of `re.search()`. We've printed out the types for `sender` and `sender.group()` so that we can see the difference. It looks like `sender` is an `re` match object, which we can't search with `re.search()`. However, `sender.group()` is a string, precisely what `re.search()` was built for.\n",
    "\n",
    "Let's see what `s_email` and `s_name` look like.\n",
    "```python\n",
    "print(s_email)\n",
    "print(s_name)\n",
    "```\n",
    "Again, we have match objects. Every time we apply `re.search()` to strings, it produces match objects. We have to turn them into string objects.\n",
    "\n",
    "Before we do this, recall that if there is no `From:` field, `sender` would have the value of `None`, and so too would `s_email` and `s_name`. Hence, we have to check for this scenario again so that the script doesn't break unexpectedly. Let's see how to construct the code with `s_email` first.\n",
    "```python\n",
    "# Step 3A: assign email address as string to a variable.\n",
    "if s_email is not None:\n",
    "    sender_email = s_email.group()\n",
    "else:\n",
    "    sender_email = None\n",
    "\n",
    "# Add email address to dictionary.\n",
    "emails_dict[\"sender_email\"] = sender_email\n",
    "```\n",
    "In __Step 3A__, we use an `if` statement to check that `s_email` is not `None`, otherwise it would throw an error and break the script.\n",
    "\n",
    "Then, we simply convert the `s_email` match object into a string and assign it to the `sender_email` variable. We add this to the `emails_dict` dictionary, which will make it incredibly easy for us to turn the details into a pandas dataframe later on.\n",
    "\n",
    "We do almost exactly the same for `s_name` in Step 3B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Step 3B: remove unwanted substrings, assign to variable.\n",
    "if s_name is not None:\n",
    "    sender_name = re.sub(\"\\s*<\", \"\", re.sub(\":\\s*\", \"\", s_name.group()))\n",
    "else:\n",
    "    sender_name = None\n",
    "\n",
    "# Add sender's name to dictionary.\n",
    "emails_dict[\"sender_name\"] = sender_name\n",
    "```\n",
    "Just as we did before, we first check that `s_name` isn't `None` in Step 3B.\n",
    "\n",
    "Then, we use the `re` module's `re.sub()` function twice before assigning the string to a variable. First, we remove the colon and any whitespace characters between it and the name. We do this by substituting `:\\s*` with an empty string `\"\"`. Then, we remove whitespace characters and the angle bracket on the other side of the name, again substituting it with an empty string. Finally, after assigning the string to `sender_name`, we add it to the dictionary.\n",
    "\n",
    "Let's check out our results.\n",
    "```python\n",
    "print(sender_email)\n",
    "print(sender_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. We've isolated the email address and the sender's name. We've also added them to the dictionary, which will come into play soon.\n",
    "\n",
    "Now that we've found the sender's email address and name, we do exactly the same set of steps to acquire the recipient's email address and name for the dictionary.\n",
    "\n",
    "First, we find the the `To:` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "recipient = re.search(r'To:.*', item)\n",
    "```\n",
    "Next, we pre-empt the scenario where `recipient` in `None`.\n",
    "```python\n",
    "if recipient is not None:\n",
    "    r_email = re.search(r'\\w\\S*@.*\\w', recipient.group())\n",
    "    r_name = re.search(r':.*<', recipient.group())\n",
    "else:\n",
    "    r_email = None\n",
    "    r_name = None\n",
    "```\n",
    "If `recipient` isn't `None`, we use `re.search()` to find the match object containing the email address and the recipient's name. Otherwise, we pass `r_email` and `r_name` the value of None.\n",
    "\n",
    "Then, we turn the match objects into strings and add them to the dictionary.\n",
    "```python\n",
    "if r_email is not None:\n",
    "    recipient_email = r_email.group()\n",
    "else:\n",
    "    recipient_email = None\n",
    "\n",
    "emails_dict[\"recipient_email\"] = recipient_email\n",
    "\n",
    "if r_name is not None:\n",
    "    recipient_name = re.sub(\"\\s*<\", \"\", re.sub(\":\\s*\", \"\", r_name.group()))\n",
    "else:\n",
    "    recipient_name = None\n",
    "\n",
    "emails_dict[\"recipient_name\"] = recipient_name\n",
    "```\n",
    "Because the structure of the `From:` and `To:` fields are the same, we can use the same code for both. We need to tailor slightly different code for the other fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Getting the date of the email__\n",
    "```python\n",
    "for item in contents:\n",
    "    emails_dict = {}\n",
    "    \n",
    "    date_field = re.search(r'Date:.*', item)\n",
    "```\n",
    "We acquire the `Date:` field with the same code for the `From:` and `To:` fields.\n",
    "\n",
    "And, just as we do for those two fields, we check that the `Date:` field, assigned to the `date_field` variable, is not `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if date_field is not None:\n",
    "    date = re.search(r\"\\d+\\s\\w+\\s\\d+\", date_field.group())\n",
    "else:\n",
    "    date = None\n",
    "\n",
    "print(date_field.group())\n",
    "```\n",
    "We've printed out `date_field.group()` so that we can see the structure of the string more clearly. It includes the day, the date in DD MMM YYYY format, and the time. We want just the date. The code for the date is largely the same as for names and email addresses but simpler. Perhaps the only puzzler here is the regex pattern, `\\d+\\s\\w+\\s\\d+`.\n",
    "\n",
    "The date starts with a number. Hence, we use `\\d` to account for it. However, as the DD part of the date, it could be either one or two digits. Here is where `+` becomes important. In regex, `+` matches 1 or more instances of a pattern on its left. `\\d+` would thus match the DD part of the date no matter if it is one or two digits.\n",
    "\n",
    "After that, there's a space. This is accounted for by `\\s`, which looks for whitespace characters. The month is made up of three alphabetical letters, hence `\\w+`. Then it hits another space, `\\s`. The year is made up of numbers, so we use `\\d+` once more.\n",
    "\n",
    "The full pattern, `\\d+\\s\\w+\\s\\d+`, works because it is a precise pattern bounded on both sides by whitespace characters.\n",
    "\n",
    "Next, we do the same check for a value of `None` as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if date is not None:\n",
    "    date_sent = date.group()\n",
    "    date_star = date_star_test.group()\n",
    "else:\n",
    "    date_sent = None\n",
    "\n",
    "emails_dict[\"date_sent\"] = date_sent\n",
    "```\n",
    "If `date` is not `None`, we turn it from a match object into a string and assign it to the variable `date_sent`. We then insert it into the dictionary.\n",
    "\n",
    "Before we go on, we should note a crucial point. `+` and `*`seem similar but they can produce very different results. Let's use the date string here as an example.\n",
    "```python\n",
    "date = re.search(r\"\\d+\\s\\w+\\s\\d+\", date_field.group())\n",
    "\n",
    "# What happens when we use * instead?\n",
    "date_star_test = re.search(r\"\\d*\\s\\w*\\s\\d*\", date_field.group())\n",
    "\n",
    "date_sent = date.group()\n",
    "date_star = date_star_test.group()\n",
    "\n",
    "print(date_sent)\n",
    "print(date_star)\n",
    "```\n",
    "If we use `*`, we'd be matching zero or more occurrences. `+` matches one or more occurrences. We've printed the results for both scenarios. It's a big difference. As you can see, `+` acquires the full date whereas `*` gets a space and the digit `1`.\n",
    "\n",
    "Next up, the subject line of the email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Getting the email subject__\n",
    "\n",
    "As before, we use the same code and code structure to acquire the information we need.\n",
    "```python\n",
    "for item in contents: # First two lines again so that Jupyter runs the code.\n",
    "    emails_dict = {}\n",
    "\n",
    "    subject_field = re.search(r\"Subject: .*\", item)\n",
    "\n",
    "    if subject_field is not None:\n",
    "        subject = re.sub(r\"Subject: \", \"\", subject_field.group())\n",
    "    else:\n",
    "        subject = None\n",
    "\n",
    "    emails_dict[\"subject\"] = subject\n",
    "```\n",
    "We're becoming more familiar with the use of regex now, aren't we? It's largely the same code as before, except that we substitute `\"Subject: \"` with an empty string to get only the subject itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Getting the body of the email__\n",
    "\n",
    "The last item to insert into our dictionary is the body of the email.\n",
    "```python\n",
    "full_email = email.message_from_string(item)\n",
    "body = full_email.get_payload()\n",
    "emails_dict[\"email_body\"] = body\n",
    "```\n",
    "Separating the header from the body of an email is an awfully complicated task, especially when many of the headers are different in one way or another. Consistency is seldom found in raw unorganised data. Luckily for us, the work's already been done. Python's `email` package is highly adept at this task.\n",
    "\n",
    "Remember that we've already imported the package earlier. Now, we apply its `message_from_string()` function to `item`, to turn the full email into an `email` Message object. A Message object consists of a header and a payload, which correspond to the header and body of an email.\n",
    "\n",
    "Next, we apply its `get_payload()` function on the Message object. This function isolates the body of the email. We assign it to the variable `body`, which we then insert into our `emails_dict` dictionary under the key `\"email_body\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Why the email package and not regex for the body__\n",
    "\n",
    "You may ask, why use the `email` package rather than regex? This is because there's no good way to do it with regex at the moment that doesn't require significant amounts of cleaning up. It would mean another sheet of code that probably deserves its own tutorial.\n",
    "\n",
    "It's worth checking out how we arrive at decisions like this one. However, we need to understand what square brackets, `[ ]`, mean in regex before we can do that.\n",
    "\n",
    "`[ ]` matches any character placed inside them. For instance, if we want to find `\"a\"`, `\"b\"`, or `\"c\"` in a string, we can use `[abc]` as the pattern. The patterns we discussed above apply as well. `[\\w\\s]` would find either alphanumeric or whitespace characters. The exception is `.`, which becomes a literal period within square brackets.\n",
    "\n",
    "Now, we can better understand how we made the decision to use the email package instead.\n",
    "\n",
    "A peek at the data set reveals that email headers stop at the strings `\"Status: 0\"` or `\"Status: R0\"`, and end before the string `\"From r\"` of the next email. We could thus use `Status:\\s*\\w*\\n*[\\s\\S]*From\\sr*` to acquire only the email body. `[\\s\\S]*` works for large chunks of text, numbers, and punctuation because it searches for either whitespace or non-whitespace characters.\n",
    "\n",
    "Unfortunately, some emails have more than one `\"Status:\"` string and others don't contain `\"From r\"`, which means that we would split the emails into more or less than the number of dictionaries in the emails list. They would not match with the other categories we already have. It becomes problematic when working with pandas. Hence, we elected to leverage the `email` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Greate the list of dictionaries__\n",
    "\n",
    "Finally, append the dictionary, `emails_dict`, to the `emails` list:\n",
    "```python\n",
    "emails.append(emails_dict)\n",
    "```\n",
    "You might want to print the `emails` list at this point to see how it looks. You can also run `print(len(emails_dict))` to see how many dictionaries, and therefore emails, are in the list. As we mentioned before, the full Corpus contains 3977. Our little test file contains seven. Here's the code in full:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails: 7\n",
      "\n",
      "\n",
      "sender_email: james_ngola2002@maktoob.com\n",
      "sender_name: \"MR. JAMES NGOLA.\"\n",
      "recipient_email: james_ngola2002@maktoob.com\n",
      "recipient_name: None\n",
      "date_sent: 31 Oct 2002\n",
      "subject: URGENT BUSINESS ASSISTANCE AND PARTNERSHIP\n",
      "email_body: email body here\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import email\n",
    "\n",
    "emails = []\n",
    "\n",
    "fh = open(r\"test_emails.txt\", \"r\").read()\n",
    "\n",
    "contents = re.split(r\"From r\",fh)\n",
    "contents.pop(0)\n",
    "\n",
    "for item in contents:\n",
    "    emails_dict = {}\n",
    "\n",
    "    sender = re.search(r\"From:.*\", item)\n",
    "\n",
    "    if sender is not None:\n",
    "        s_email = re.search(r\"\\w\\S*@.*\\w\", sender.group())\n",
    "        s_name = re.search(r\":.*<\", sender.group())\n",
    "    else:\n",
    "        s_email = None\n",
    "        s_name = None\n",
    "\n",
    "    if s_email is not None:\n",
    "        sender_email = s_email.group()\n",
    "    else:\n",
    "        sender_email = None\n",
    "\n",
    "    emails_dict[\"sender_email\"] = sender_email\n",
    "\n",
    "    if s_name is not None:\n",
    "        sender_name = re.sub(\"\\s*<\", \"\", re.sub(\":\\s*\", \"\", s_name.group()))\n",
    "    else:\n",
    "        sender_name = None\n",
    "\n",
    "    emails_dict[\"sender_name\"] = sender_name\n",
    "\n",
    "    recipient = re.search(r\"To:.*\", item)\n",
    "\n",
    "    if recipient is not None:\n",
    "        r_email = re.search(r\"\\w\\S*@.*\\w\", recipient.group())\n",
    "        r_name = re.search(r\":.*<\", recipient.group())\n",
    "    else:\n",
    "        r_email = None\n",
    "        r_name = None\n",
    "\n",
    "    if r_email is not None:\n",
    "        recipient_email = r_email.group()\n",
    "    else:\n",
    "        recipient_email = None\n",
    "\n",
    "    emails_dict[\"recipient_email\"] = recipient_email\n",
    "\n",
    "    if r_name is not None:\n",
    "        recipient_name = re.sub(\"\\s*<\", \"\", re.sub(\":\\s*\", \"\", r_name.group()))\n",
    "    else:\n",
    "        recipient_name = None\n",
    "\n",
    "    emails_dict[\"recipient_name\"] = recipient_name\n",
    "\n",
    "    date_field = re.search(r\"Date:.*\", item)\n",
    "\n",
    "    if date_field is not None:\n",
    "        date = re.search(r\"\\d+\\s\\w+\\s\\d+\", date_field.group())\n",
    "    else:\n",
    "        date = None\n",
    "\n",
    "    if date is not None:\n",
    "        date_sent = date.group()\n",
    "    else:\n",
    "        date_sent = None\n",
    "\n",
    "    emails_dict[\"date_sent\"] = date_sent\n",
    "\n",
    "    subject_field = re.search(r\"Subject: .*\", item)\n",
    "\n",
    "    if subject_field is not None:\n",
    "        subject = re.sub(r\"Subject: \", \"\", subject_field.group())\n",
    "    else:\n",
    "        subject = None\n",
    "\n",
    "    emails_dict[\"subject\"] = subject\n",
    "\n",
    "    # \"item\" substituted with \"email content here\" so full email not displayed.\n",
    "\n",
    "    full_email = email.message_from_string(item)\n",
    "    body = full_email.get_payload()\n",
    "    emails_dict[\"email_body\"] = \"email body here\"\n",
    "\n",
    "    emails.append(emails_dict)\n",
    "\n",
    "# Print number of dictionaries, and hence, emails, in the list.\n",
    "print(\"Number of emails: \" + str(len(emails_dict)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print first item in the emails list to see how it looks.\n",
    "for key, value in emails[0].items():\n",
    "    print(str(key) + \": \" + str(emails[0][key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've printed out the first item in the `emails` list, and it's clearly a dictionary with key and value pairs. Because we used a `for` loop, every dictionary has the same keys but different values.\n",
    "\n",
    "We've substituted `item` with `\"email content here\"` so that we don't print out the entire mass of the email and clog up our screens. If you're printing this at home using the actual data set, you'll see the entire email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Manipulating data with pandas__\n",
    "\n",
    "With dictionaries in a list, we've made it infinitely easy for the pandas library to do its job. Each key will become a column title, and each value becomes a row in that column.\n",
    "\n",
    "All we have to do is apply the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "emails_df = pd.DataFrame(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_sent</th>\n",
       "      <th>email_body</th>\n",
       "      <th>recipient_email</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>sender_email</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 Oct 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>james_ngola2002@maktoob.com</td>\n",
       "      <td>None</td>\n",
       "      <td>james_ngola2002@maktoob.com</td>\n",
       "      <td>\"MR. JAMES NGOLA.\"</td>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31 Oct 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>R@M</td>\n",
       "      <td>None</td>\n",
       "      <td>bensul2004nng@spinfinder.com</td>\n",
       "      <td>\"Mr. Ben Suleman\"</td>\n",
       "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31 Oct 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>obong_715@epatra.com</td>\n",
       "      <td>None</td>\n",
       "      <td>obong_715@epatra.com</td>\n",
       "      <td>\"PRINCE OBONG ELEME\"</td>\n",
       "      <td>GOOD DAY TO YOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31 Oct 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>webmaster@aclweb.org</td>\n",
       "      <td>None</td>\n",
       "      <td>obong_715@epatra.com</td>\n",
       "      <td>\"PRINCE OBONG ELEME\"</td>\n",
       "      <td>GOOD DAY TO YOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Nov 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>m_abacha03@www.com</td>\n",
       "      <td>None</td>\n",
       "      <td>m_abacha03@www.com</td>\n",
       "      <td>\"Maryam Abacha\"</td>\n",
       "      <td>I Need Your Assistance.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_sent       email_body              recipient_email recipient_name  \\\n",
       "0  31 Oct 2002  email body here  james_ngola2002@maktoob.com           None   \n",
       "1  31 Oct 2002  email body here                          R@M           None   \n",
       "2  31 Oct 2002  email body here         obong_715@epatra.com           None   \n",
       "3  31 Oct 2002  email body here         webmaster@aclweb.org           None   \n",
       "4   1 Nov 2002  email body here           m_abacha03@www.com           None   \n",
       "\n",
       "                   sender_email           sender_name  \\\n",
       "0   james_ngola2002@maktoob.com    \"MR. JAMES NGOLA.\"   \n",
       "1  bensul2004nng@spinfinder.com     \"Mr. Ben Suleman\"   \n",
       "2          obong_715@epatra.com  \"PRINCE OBONG ELEME\"   \n",
       "3          obong_715@epatra.com  \"PRINCE OBONG ELEME\"   \n",
       "4            m_abacha03@www.com       \"Maryam Abacha\"   \n",
       "\n",
       "                                      subject  \n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP  \n",
       "1         URGENT ASSISTANCE /RELATIONSHIP (P)  \n",
       "2                             GOOD DAY TO YOU  \n",
       "3                             GOOD DAY TO YOU  \n",
       "4                     I Need Your Assistance.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipe symbol, `|`, looks for characters on either side of itself. For instance, `a|b` looks for either `a` or `b`.\n",
    "\n",
    "`|` might seem to do the same as `[ ]`, but they really are different. Suppose we want to match either `\"crab\"`, `\"lobster\"`, or `\"isopod\"`. Using `crab|lobster|isopod` would make more sense than `[crablobsterisopod]`, wouldn't it? The former would look for each whole word, whereas the latter would look for every single letter.\n",
    "\n",
    "Now, let's use `|` to find all the emails sent from one or another domain name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_sent</th>\n",
       "      <th>email_body</th>\n",
       "      <th>recipient_email</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>sender_email</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 Oct 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>james_ngola2002@maktoob.com</td>\n",
       "      <td>None</td>\n",
       "      <td>james_ngola2002@maktoob.com</td>\n",
       "      <td>\"MR. JAMES NGOLA.\"</td>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31 Oct 2002</td>\n",
       "      <td>email body here</td>\n",
       "      <td>R@M</td>\n",
       "      <td>None</td>\n",
       "      <td>bensul2004nng@spinfinder.com</td>\n",
       "      <td>\"Mr. Ben Suleman\"</td>\n",
       "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_sent       email_body              recipient_email recipient_name  \\\n",
       "0  31 Oct 2002  email body here  james_ngola2002@maktoob.com           None   \n",
       "1  31 Oct 2002  email body here                          R@M           None   \n",
       "\n",
       "                   sender_email         sender_name  \\\n",
       "0   james_ngola2002@maktoob.com  \"MR. JAMES NGOLA.\"   \n",
       "1  bensul2004nng@spinfinder.com   \"Mr. Ben Suleman\"   \n",
       "\n",
       "                                      subject  \n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP  \n",
       "1         URGENT ASSISTANCE /RELATIONSHIP (P)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df[emails_df['sender_email'].str.contains('maktoob|spinfinder')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view emails from individual cells too. To do this, we go through four steps. In Step 1, we find the index of the row where the `\"sender_email\"` column contains the string `\"@maktoob\"`. Notice how we use regex to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: find the index where the \"sender_email\" column contains \"@maktoob.com\".\n",
    "index = emails_df[emails_df[\"sender_email\"].str.contains(r\"\\w\\S*@maktoob.com\")].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Step 2, we use the index to find the email address, which the `loc[]` method returns as a Series object with several different properties. We print it out below to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    james_ngola2002@maktoob.com\n",
      "Name: sender_email, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Step 2: use the index to find the value of the cell in the \"sender_email\" column.\n",
    "# The result is returned as pandas Series object\n",
    "address_Series = emails_df.loc[index][\"sender_email\"]\n",
    "print(address_Series)\n",
    "print(type(address_Series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Step 3, we extract the email address from the Series object as we would items from a list. You can see that its type is now class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "james_ngola2002@maktoob.com\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Step 3: extract the email address, which is at index 0 in the Series object.\n",
    "address_string = address_Series[0]\n",
    "print(address_string)\n",
    "print(type(address_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 is where we extract the email body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['email body here']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: find the value of the \"email_body\" column where the \"sender email\" column is address_string.\n",
    "print(emails_df[emails_df[\"sender_email\"] == address_string][\"email_body\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Step 4, `emails_df['sender_email'] == \"james_ngola2002@maktoob.com\"` finds the row where the `sender_email` column contains the value `\"james_ngola2002@maktoob.com\"`. Next, `['email_body'].values` finds the value of the `email_body` column in that same row. Finally, we print out the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
